<!-- overview -->
# Installing kubeadm

This page shows how to install the `kubeadm` toolbox.
For information on how to create a cluster with kubeadm once you have performed this installation process,
see the.

## Before you begin

* A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions
  based on Debian and Red Hat, and those distributions without a package manager.
* 2 GB or more of RAM per machine (any less will leave little room for your apps).
* 2 CPUs or more.
* Full network connectivity between all machines in the cluster (public or private network is fine).
* Unique hostname, MAC address, and product_uuid for every node. See [here](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#verify-mac-address) for more details.
* Certain ports are open on your machines. See [here](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports) for more details.
* Swap configuration. The default behavior of a kubelet was to fail to start if swap memory was detected on a node.
  Swap has been supported since v1.22. And since v1.28, Swap is supported for cgroup v2 only; the NodeSwap feature
  gate of the kubelet is beta but disabled by default.
  * You **MUST** disable swap if the kubelet is not properly configured to use swap. For example, `sudo swapoff -a`
    will disable swapping temporarily. To make this change persistent across reboots, make sure swap is disabled in
    config files like `/etc/fstab`, `systemd.swap`, depending how it was configured on your system.

<!-- steps -->

## Verify the MAC address and product_uuid are unique for every node {#verify-mac-address}

* You can get the MAC address of the network interfaces using the command `ip link` or `ifconfig -a`
* The product_uuid can be checked by using the command `sudo cat /sys/class/dmi/id/product_uuid`

It is very likely that hardware devices will have unique addresses, although some virtual machines may have
identical values. Kubernetes uses these values to uniquely identify the nodes in the cluster.
If these values are not unique to each node, the installation process
may [fail](https://github.com/kubernetes/kubeadm/issues/31).

## Check network adapters

If you have more than one network adapter, and your Kubernetes components are not reachable on the default
route, we recommend you add IP route(s) so Kubernetes cluster addresses go via the appropriate adapter.

## Check required ports

These [required ports](https://kubernetes.io/docs/reference/networking/ports-and-protocols/)
need to be open in order for Kubernetes components to communicate with each other.
You can use tools like netcat to check if a port is open. For example:

```shell
nc 127.0.0.1 6443
```

The pod network plugin you use may also require certain ports to be
open. Since this differs with each pod network plugin, please see the
documentation for the plugins about what port(s) those need.

## Installing a container runtime

To run containers in Pods, Kubernetes uses a container runtime

By default, Kubernetes uses the (CRI)
to interface with your chosen container runtime.

If you don't specify a runtime, kubeadm automatically tries to detect an installed
container runtime by scanning through a list of known endpoints.

If multiple or no container runtimes are detected kubeadm will throw an error
and will request that you specify which one you want to use.

See [container runtimes](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
for more information.

Docker Engine does not implement the [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)
which is a requirement for a container runtime to work with Kubernetes.
For that reason, an additional service [cri-dockerd](https://github.com/Mirantis/cri-dockerd)
has to be installed. cri-dockerd is a project based on the legacy built-in
Docker Engine support that was [removed](https://kubernetes.io/dockershim/) from the kubelet in version 1.24.

The tables below include the known endpoints for supported operating systems:

| Runtime                            | Path to Unix domain socket                   |
|------------------------------------|----------------------------------------------|
| containerd                         | `unix:///var/run/containerd/containerd.sock` |
| CRI-O                              | `unix:///var/run/crio/crio.sock`             |
| Docker Engine (using cri-dockerd)  | `unix:///var/run/cri-dockerd.sock`           |


## Installing kubeadm, kubelet and kubectl

You will install these packages on all of your machines:

* `kubeadm`: the command to bootstrap the cluster.

* `kubelet`: the component that runs on all of the machines in your cluster
    and does things like starting pods and containers.

* `kubectl`: the command line util to talk to your cluster.

kubeadm **will not** install or manage `kubelet` or `kubectl` for you, so you will
need to ensure they match the version of the Kubernetes control plane you want
kubeadm to install for you. If you do not, there is a risk of a version skew occurring that
can lead to unexpected, buggy behaviour. However, _one_ minor version skew between the
kubelet and the control plane is supported, but the kubelet version may never exceed the API
server version. For example, the kubelet running 1.7.0 should be fully compatible with a 1.8.0 API server,
but not vice versa.

## Install Kubernetes Cluster on Ubuntu 22.04 using kubeadm

0. Once the servers are ready, update them.

   ```shell
   sudo apt update
   sudo apt -y full-upgrade
   [ -f /var/run/reboot-required ] && sudo reboot -f
   ```

1. Update the `apt` package index and install packages needed to use the Kubernetes `apt` repository:

   ```shell
   sudo apt-get update
   # apt-transport-https may be a dummy package; if so, you can skip that package
   sudo apt-get install -y apt-transport-https ca-certificates curl
   ```

2. Install kubelet, kubeadm and kubectl

   ```shell
   curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
   echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
   ```

3. Update the `apt` package index, install kubelet, kubeadm and kubectl, and pin their version:

   ```shell
   sudo apt update
   sudo apt install wget curl vim git kubelet kubeadm kubectl -y
   sudo apt-mark hold kubelet kubeadm kubectl
   ```

4. Confirm installation by checking the version of kubectl.

   ```shell
   kubectl version --client
   kubeadm version
   ```

5. Disable Swap Space

   ```shell
   sudo swapoff -a
   sudo sed -i.bak -r 's/(.+ swap .+)/#\1/' /etc/fstab
   cat /etc/fstab
   ```

6. Enable kernel modules and configure sysctl.

   ```shell
   # Configure persistent loading of modules
   sudo tee /etc/modules-load.d/k8s.conf <<EOF
   overlay
   br_netfilter
   EOF

   # Ensure you load modules
   sudo modprobe overlay
   sudo modprobe br_netfilter

   # Set up required sysctl params
   sudo tee /etc/sysctl.d/kubernetes.conf<<EOF
   net.bridge.bridge-nf-call-ip6tables = 1
   net.bridge.bridge-nf-call-iptables = 1
   net.ipv4.ip_forward = 1
   EOF

   # Reload sysctl
   sudo sysctl --system
   ```

## Install Container runtime (all nodes)

### Docker runtime

   ```shell
   # Add repo and Install packages
   sudo apt update
   sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
   curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
   sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
   sudo apt update
   sudo apt install -y containerd.io docker-ce docker-ce-cli

   # Create required directories
   sudo mkdir -p /etc/systemd/system/docker.service.d

   # Create daemon json config file
   sudo tee /etc/docker/daemon.json <<EOF
   {
   "exec-opts": ["native.cgroupdriver=systemd"],
   "log-driver": "json-file",
   "log-opts": {
      "max-size": "100m"
   },
   "storage-driver": "overlay2"
   }
   EOF

   # Start and enable Services
   sudo systemctl daemon-reload 
   sudo systemctl restart docker
   sudo systemctl enable docker
   ```

### Install Mirantis cri-dockerd as Docker Engine shim for Kubernetes

Ensure Docker service is running before you proceed

   ```shell
   systemctl status docker
   ```

Download the archive file from Github cri-dockerd releases page.

   ```shell
   VER=$(curl -s https://api.github.com/repos/Mirantis/cri-dockerd/releases/latest|grep tag_name | cut -d '"' -f 4|sed 's/v//g')
   echo $VER

   wget https://github.com/Mirantis/cri-dockerd/releases/download/v${VER}/cri-dockerd-${VER}.amd64.tgz
   tar xvf cri-dockerd-${VER}.amd64.tgz

   sudo mv cri-dockerd/cri-dockerd /usr/local/bin/

   cri-dockerd --version

   wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.service
   wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.socket
   sudo mv cri-docker.socket cri-docker.service /etc/systemd/system/
   sudo sed -i -e 's,/usr/bin/cri-dockerd,/usr/local/bin/cri-dockerd,' /etc/systemd/system/cri-docker.service

   sudo systemctl daemon-reload
   sudo systemctl enable cri-docker.service
   sudo systemctl enable --now cri-docker.socket

   # Checking
   systemctl status cri-docker.socket
   ```

### Using cri-dockerd on new Kubernetes cluster

   ```shell
   sudo kubeadm config images pull --cri-socket /run/cri-dockerd.sock 
   ```

### Bootstrap with shared endpoint (DNS name for control plane API)

   ```shell
      sudo vim /etc/hosts
      
      192.168.1.XXX node01.<name>.local
      192.168.1.XXX node02.<name>.local
      192.168.1.XXX node03.<name>.local
   ```

   ```shell
      kubeadm init \
      --pod-network-cidr=10.142.0.0/16 \
      --cri-socket /run/cri-dockerd.sock  \
      --upload-certs \
      --control-plane-endpoint=node01.<name>.local
   ```

   ```shell
   mkdir -p $HOME/.kube
   sudo cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
   sudo chown $(id -u):$(id -g) $HOME/.kube/config

   kubectl cluster-info
   ```

### Download Calico CNI plugin & modify pod cidr

   ```shell
   curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml -O calico.yaml

   nano calico.yaml

   - name: CALICO_IPV4POOL_CIDR
     value: "10.142.0.0/16"
   ```

   ```shell
   kubectl apply -f calico.yaml

   watch kubectl get pods -n kube-system
   ```

Remove the taints on the control plane so that you can schedule pods on it

   ```shell
   kubectl taint nodes --all node-role.kubernetes.io/control-plane-
   kubectl taint nodes --all node-role.kubernetes.io/master-
   ```

   ```shell
   kubectl get nodes -o wide   
   ```
Add taints on control plane
   ```shell
   kubectl taint nodes [control-plane hostname] node-role.kubernetes.io/control-plane:NoSchedule
   ```

### Join worker nodes

NOTE: on other servers

   ```shell
   kubeadm token create --print-join-command
   ```

   ```shell
   kubeadm join node01.<name>.local:6443 --token 4sl1l4.9zttrthukh2fuot2 \
   --discovery-token-ca-cert-hash sha256:1049a0fd842b1fb4d4f42173b63e7163b20c6ade686a1988089fe49bad43eebf \
      --cri-socket /run/cri-dockerd.sock
   ```

## References

* <https://computingforgeeks.com/install-kubernetes-cluster-ubuntu-jammy/>
* <https://computingforgeeks.com/install-mirantis-cri-dockerd-as-docker-engine-shim-for-kubernetes/>
* <https://computingforgeeks.com/setup-prometheus-and-grafana-on-kubernetes/>
